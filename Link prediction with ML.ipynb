{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 사용할 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Node feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.077034</td>\n",
       "      <td>-0.065027</td>\n",
       "      <td>-0.135552</td>\n",
       "      <td>0.007305</td>\n",
       "      <td>-0.019618</td>\n",
       "      <td>-0.129522</td>\n",
       "      <td>-0.394962</td>\n",
       "      <td>-0.096774</td>\n",
       "      <td>-0.549495</td>\n",
       "      <td>-0.229680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329416</td>\n",
       "      <td>0.634487</td>\n",
       "      <td>-0.183202</td>\n",
       "      <td>0.280506</td>\n",
       "      <td>0.017737</td>\n",
       "      <td>-0.141899</td>\n",
       "      <td>0.300271</td>\n",
       "      <td>-0.148616</td>\n",
       "      <td>0.042472</td>\n",
       "      <td>-0.092819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.090406</td>\n",
       "      <td>-0.055498</td>\n",
       "      <td>-0.199454</td>\n",
       "      <td>-0.073101</td>\n",
       "      <td>0.129980</td>\n",
       "      <td>-0.168792</td>\n",
       "      <td>-0.498300</td>\n",
       "      <td>0.012366</td>\n",
       "      <td>-0.517318</td>\n",
       "      <td>-0.344800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262000</td>\n",
       "      <td>0.534585</td>\n",
       "      <td>-0.284113</td>\n",
       "      <td>0.193362</td>\n",
       "      <td>-0.017993</td>\n",
       "      <td>0.133143</td>\n",
       "      <td>0.415925</td>\n",
       "      <td>-0.205510</td>\n",
       "      <td>-0.057315</td>\n",
       "      <td>-0.221824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036018</td>\n",
       "      <td>-0.276833</td>\n",
       "      <td>-0.006313</td>\n",
       "      <td>0.365836</td>\n",
       "      <td>-0.054446</td>\n",
       "      <td>-0.388111</td>\n",
       "      <td>-0.310889</td>\n",
       "      <td>-0.128666</td>\n",
       "      <td>-0.691407</td>\n",
       "      <td>-0.319269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416217</td>\n",
       "      <td>0.616074</td>\n",
       "      <td>-0.175263</td>\n",
       "      <td>0.126960</td>\n",
       "      <td>0.048850</td>\n",
       "      <td>0.135687</td>\n",
       "      <td>0.397666</td>\n",
       "      <td>0.022077</td>\n",
       "      <td>0.115069</td>\n",
       "      <td>-0.050359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.103949</td>\n",
       "      <td>0.141362</td>\n",
       "      <td>-0.234800</td>\n",
       "      <td>0.038294</td>\n",
       "      <td>0.029006</td>\n",
       "      <td>-0.042764</td>\n",
       "      <td>-0.260278</td>\n",
       "      <td>-0.073697</td>\n",
       "      <td>-0.443563</td>\n",
       "      <td>-0.339663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144633</td>\n",
       "      <td>0.384818</td>\n",
       "      <td>-0.301781</td>\n",
       "      <td>0.235658</td>\n",
       "      <td>-0.114685</td>\n",
       "      <td>0.138715</td>\n",
       "      <td>0.108334</td>\n",
       "      <td>-0.113345</td>\n",
       "      <td>-0.067795</td>\n",
       "      <td>-0.181579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.031268</td>\n",
       "      <td>0.008753</td>\n",
       "      <td>-0.352797</td>\n",
       "      <td>-0.175202</td>\n",
       "      <td>0.124375</td>\n",
       "      <td>-0.166064</td>\n",
       "      <td>-0.467233</td>\n",
       "      <td>-0.056786</td>\n",
       "      <td>-0.466632</td>\n",
       "      <td>-0.372931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415152</td>\n",
       "      <td>0.578069</td>\n",
       "      <td>-0.262672</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>-0.017925</td>\n",
       "      <td>0.197143</td>\n",
       "      <td>0.425531</td>\n",
       "      <td>-0.134342</td>\n",
       "      <td>0.073450</td>\n",
       "      <td>-0.063862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.077034 -0.065027 -0.135552  0.007305 -0.019618 -0.129522 -0.394962   \n",
       "1  0.090406 -0.055498 -0.199454 -0.073101  0.129980 -0.168792 -0.498300   \n",
       "2  0.036018 -0.276833 -0.006313  0.365836 -0.054446 -0.388111 -0.310889   \n",
       "3  0.103949  0.141362 -0.234800  0.038294  0.029006 -0.042764 -0.260278   \n",
       "4 -0.031268  0.008753 -0.352797 -0.175202  0.124375 -0.166064 -0.467233   \n",
       "\n",
       "         7         8         9   ...        22        23        24        25  \\\n",
       "0 -0.096774 -0.549495 -0.229680  ...  0.329416  0.634487 -0.183202  0.280506   \n",
       "1  0.012366 -0.517318 -0.344800  ...  0.262000  0.534585 -0.284113  0.193362   \n",
       "2 -0.128666 -0.691407 -0.319269  ...  0.416217  0.616074 -0.175263  0.126960   \n",
       "3 -0.073697 -0.443563 -0.339663  ...  0.144633  0.384818 -0.301781  0.235658   \n",
       "4 -0.056786 -0.466632 -0.372931  ...  0.415152  0.578069 -0.262672  0.017259   \n",
       "\n",
       "         26        27        28        29        30        31  \n",
       "0  0.017737 -0.141899  0.300271 -0.148616  0.042472 -0.092819  \n",
       "1 -0.017993  0.133143  0.415925 -0.205510 -0.057315 -0.221824  \n",
       "2  0.048850  0.135687  0.397666  0.022077  0.115069 -0.050359  \n",
       "3 -0.114685  0.138715  0.108334 -0.113345 -0.067795 -0.181579  \n",
       "4 -0.017925  0.197143  0.425531 -0.134342  0.073450 -0.063862  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feature = pd.read_csv('node_feature.txt', sep=\" \",header=None)\n",
    "node_feature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Train edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 12588\n",
      "Number of edges: 14322\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_edgelist('train_edges.txt', delimiter=' ', create_using=nx.DiGraph(), nodetype=int)\n",
    "nodes = list(G.nodes())\n",
    "n = G.number_of_nodes()\n",
    "m = G.number_of_edges()\n",
    "print('Number of nodes:', n)\n",
    "print('Number of edges:', m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Test edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node1</th>\n",
       "      <th>node2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11468</td>\n",
       "      <td>1677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3508</td>\n",
       "      <td>8904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6724</td>\n",
       "      <td>2318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11662</td>\n",
       "      <td>9673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2035</td>\n",
       "      <td>3693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node1  node2\n",
       "0  11468   1677\n",
       "1   3508   8904\n",
       "2   6724   2318\n",
       "3  11662   9673\n",
       "4   2035   3693"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_edges = pd.read_csv('unlabeled_edges.txt', sep=\" \",header=None)\n",
    "test_edges.columns = ['node1', 'node2']\n",
    "test_edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Node feature와 Graph 관련 Feature를 추가하여, 데이터 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node Feature 정보를 활용하여, 각 Column에 대한 더한 값과 차이의 값을 Feature로 추가한다.\n",
    "\n",
    "또한 Graph 정보는 두 노드의 degree와 in_degree의 더한 값과 차이의 값을 Feature로 추가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Train Dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((2*m, 68))\n",
    "y_train = np.zeros(2*m)\n",
    "\n",
    "for i,edge in enumerate(G.edges()):\n",
    "    # an edge\n",
    "    for col in range(node_feature.shape[1]):\n",
    "        X_train[i,2*col] = node_features[col][edge[0]] + node_features[col][edge[1]]\n",
    "        X_train[i,2*col+1] = abs(node_features[col][edge[0]] - node_features[col][edge[1]])\n",
    "    \n",
    "    X_train[i,64] = G.degree(edge[0]) + G.degree(edge[1]) \n",
    "    X_train[i,65] = abs(G.degree(edge[0]) - G.degree(edge[1]))\n",
    "    X_train[i,66] = G.in_degree(edge[0]) + G.in_degree(edge[1])\n",
    "    X_train[i,67] = abs(G.in_degree(edge[0]) - G.in_degree(edge[1]))\n",
    "    \n",
    "    y_train[i] = 1\n",
    "    \n",
    "    # a randomly generated pair of nodes\n",
    "    n1 = randint(0, n-1)\n",
    "    n2 = randint(0, n-1)\n",
    "    \n",
    "    #an edge\n",
    "    for col in range(node_feature.shape[1]):\n",
    "        X_train[m + i,2*col] = node_features[col][n1] + node_features[col][n2]\n",
    "        X_train[m + i,2*col+1] = abs(node_features[col][n1] - node_features[col][n2])\n",
    "    \n",
    "    X_train[m+i,64] = G.degree(edge[0]) + G.degree(edge[1]) \n",
    "    X_train[m+i,65] = abs(G.degree(edge[0]) - G.degree(edge[1]))\n",
    "    X_train[m+i,66] = G.in_degree(edge[0]) + G.in_degree(edge[1])\n",
    "    X_train[m+i,67] = abs(G.in_degree(edge[0]) - G.in_degree(edge[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training matrix: (28644, 68)\n"
     ]
    }
   ],
   "source": [
    "print('Size of training matrix:', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Test Dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((test_edges.shape[0], 68))\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    # an edge\n",
    "    for col in range(node_feature.shape[1]):\n",
    "        X_test[i,2*col] = node_features[col][test_edges['node1'][i]] + node_features[col][test_edges['node2'][i]]\n",
    "        X_test[i,2*col+1] = abs(node_features[col][test_edges['node1'][i]] - node_features[col][test_edges['node2'][i]])\n",
    "    \n",
    "    X_test[i,64] = G.degree(test_edges['node1'][i]) + G.degree(test_edges['node2'][i]) \n",
    "    X_test[i,65] = abs(G.degree(test_edges['node1'][i]) - G.degree(test_edges['node2'][i]))\n",
    "    X_test[i,66] = G.in_degree(test_edges['node1'][i]) + G.in_degree(test_edges['node2'][i])\n",
    "    X_test[i,67] = abs(G.in_degree(test_edges['node1'][i]) - G.in_degree(test_edges['node2'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train 데이터의 성능 측정을 위해 Validation dataset을 10% 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=17, stratify = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use logistic regression to predict if two nodes are linked by an edge\n",
    "logit_model = LogisticRegression(solver='liblinear',random_state=34)\n",
    "logit_model.fit(X_train, y_train)\n",
    "valid_pred = logit_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.64      0.66      1432\n",
      "         1.0       0.66      0.70      0.68      1433\n",
      "\n",
      "    accuracy                           0.67      2865\n",
      "   macro avg       0.67      0.67      0.67      2865\n",
      "weighted avg       0.67      0.67      0.67      2865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForestClassifier(n_estimators = 500, max_depth = 5)\n",
    "RF_model.fit(X_train, y_train)\n",
    "valid_pred = RF_model.predict(X_valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.63      0.67      1432\n",
      "         1.0       0.67      0.74      0.70      1433\n",
      "\n",
      "    accuracy                           0.69      2865\n",
      "   macro avg       0.69      0.69      0.68      2865\n",
      "weighted avg       0.69      0.69      0.68      2865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:44:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { n_estimator } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgboost.XGBClassifier(n_estimator = 1000, learning_rate = 0.1, random_state = 100, subsample=0.8)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "valid_pred = xgb_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.77      0.76      1432\n",
      "         1.0       0.76      0.73      0.75      1433\n",
      "\n",
      "    accuracy                           0.75      2865\n",
      "   macro avg       0.75      0.75      0.75      2865\n",
      "weighted avg       0.75      0.75      0.75      2865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가장 성능이 좋은 Link prediction 모델은 XGBoost 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test에 대한 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_edges['Linked_probability'] = y_pred\n",
    "test_edges.to_csv('test_prediction.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('link_prediction')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "85ec08d3474848a4fd70a3f061c7ad7f63afeeff3d50d0d8fac292c5754d0433"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
